{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleGANS",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNgzq4TZHAc+0JVTGV2QLu8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mattberg88/Colab/blob/develop/SimpleGANS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "yKVt1AJxBlxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download jessicali9530/celeba-dataset\n"
      ],
      "metadata": {
        "id": "K27QZYc9CEj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/celeba-dataset.zip\" -d \"/content/\""
      ],
      "metadata": {
        "id": "tbHTd0VFCGQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNhzWVdiBRuW"
      },
      "outputs": [],
      "source": [
        "import abc\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential, Input\n",
        "from keras.layers import Conv2D, LeakyReLU, Flatten, Dropout, Dense, Reshape, Conv2DTranspose\n",
        "from keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def load_from_directory(filename, resize, batch_size=32,):\n",
        "    dataset = keras.preprocessing.image_dataset_from_directory(\n",
        "        filename, label_mode=None, image_size=resize, batch_size=batch_size\n",
        "    )\n",
        "    dataset = dataset.map(lambda x: (x - 127.0) / 127.0)  # make 255 values between 0 and 1\n",
        "    # dataset is of type MapDataset or map of tensors\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def load_from_npz(filename, resize, data_parm='arr_0', batch_size=32, shuffle_buffer_size=100):\n",
        "    with np.load(filename) as data:\n",
        "        dataset = data[data_parm]\n",
        "\n",
        "    dataset = [np.array(Image.fromarray(data, 'RGB').resize(size=resize)).astype('float32') for data in dataset]\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(dataset)\n",
        "    dataset = dataset.map(lambda x: (x - 255.0) / 255.0)\n",
        "\n",
        "    dataset = dataset.shuffle(shuffle_buffer_size).batch(\n",
        "        batch_size)  # shuffle (5arbat 5arabit (｡･∀･)ﾉﾞ（＾∀＾●）ﾉｼ) and batch them\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def display_sample(dataset):\n",
        "    for x in dataset:\n",
        "        plt.axis(\"off\")\n",
        "        plt.imshow((x.numpy() * 255).astype(\"int32\")[0])\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers.normalization.batch_normalization import BatchNormalization\n",
        "\n",
        "\n",
        "class CustomModel:\n",
        "    def __init__(self):\n",
        "        self.model = self.build_model()\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def build_model(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class Discriminator(CustomModel):\n",
        "    def build_model(self):\n",
        "        model = Sequential(\n",
        "            [\n",
        "                # 64x64 input\n",
        "                Conv2D(32, input_shape=(256, 256, 3), kernel_size=4, strides=2, padding=\"same\", ),\n",
        "                Conv2D(64, kernel_size=4, strides=2, padding=\"same\", ),\n",
        "                LeakyReLU(alpha=0.2),\n",
        "                BatchNormalization(),\n",
        "                # to 32x32\n",
        "                Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "                LeakyReLU(alpha=0.2),\n",
        "                BatchNormalization(),\n",
        "                # to 16x16\n",
        "                Conv2D(256, kernel_size=4, strides=2, padding=\"same\"),\n",
        "                LeakyReLU(alpha=0.2),\n",
        "                Flatten(),  # from matrix to vector\n",
        "                Dropout(0.5),  # 20% of the network is at rest\n",
        "                Dense(1, activation=\"sigmoid\"),\n",
        "            ],\n",
        "            name=\"discriminator\",\n",
        "        )\n",
        "        return model\n",
        "\n",
        "\n",
        "class Generator(CustomModel):\n",
        "    def __init__(self, latent_dim):\n",
        "        self.latent_dim = latent_dim\n",
        "        super().__init__()\n",
        "\n",
        "    def build_model(self):\n",
        "        model = keras.Sequential(\n",
        "            [\n",
        "                Input(shape=(self.latent_dim,)),\n",
        "                Dense(16 * 16 * 512),\n",
        "                Reshape((16, 16, 512)),\n",
        "                Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
        "                LeakyReLU(alpha=0.2),\n",
        "                Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "                LeakyReLU(alpha=0.2),\n",
        "                Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\"),\n",
        "                LeakyReLU(alpha=0.2),\n",
        "                Conv2DTranspose(32, kernel_size=4, strides=2, padding=\"same\"),\n",
        "                LeakyReLU(alpha=0.2),\n",
        "                BatchNormalization(),\n",
        "                Conv2D(3, kernel_size=4, padding=\"same\", activation=\"tanh\"),\n",
        "            ],\n",
        "            name=\"generator\",\n",
        "        )\n",
        "        return model\n",
        "\n",
        "\n",
        "class GAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super(GAN, self).__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super(GAN, self).compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.d_loss_metric, self.g_loss_metric]\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        # Sample random points in the latent space\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Decode them to fake images\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "        # Combine them with real images\n",
        "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "        # Assemble labels discriminating real from fake images\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "        # Add random noise to the labels - important trick!\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        # Train the discriminator\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Sample random points in the latent space\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Assemble labels that say \"all real images\"\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        # Update metrics\n",
        "        self.d_loss_metric.update_state(d_loss)\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "        return {\n",
        "            \"d_loss\": self.d_loss_metric.result(),\n",
        "            \"g_loss\": self.g_loss_metric.result(),\n",
        "        }\n",
        "\n",
        "\n",
        "class GANMonitor(keras.callbacks.Callback):\n",
        "    def __init__(self, num_img=3, latent_dim=256):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
        "        generated_images = self.model.generator(random_latent_vectors)\n",
        "        generated_images *= 255\n",
        "        generated_images.numpy()\n",
        "        for i in range(self.num_img):\n",
        "            img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
        "            img.save(\"/content/gdrive/My Drive/SimpleGANS/generated_images_7/generated_img_%03d_%d.png\" % (epoch, i))"
      ],
      "metadata": {
        "id": "vSTAkJO-Bd2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 256\n",
        "\n",
        "gan = GAN(discriminator=Discriminator().model, generator=Generator(latent_dim).model, latent_dim=latent_dim)\n",
        "gan.compile(\n",
        "    d_optimizer=Adam(learning_rate=0.0001),\n",
        "    g_optimizer=Adam(learning_rate=0.0001),\n",
        "    loss_fn=BinaryCrossentropy(),\n",
        ")"
      ],
      "metadata": {
        "id": "xdbXWaMgD8B3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_from_directory('../content/img_align_celeba',(256,256))\n"
      ],
      "metadata": {
        "id": "WE6z3Zs5En5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "checkpoint_path = \"/content/gdrive/My Drive/SimpleGANS/Checkpoint7/\"\n"
      ],
      "metadata": {
        "id": "ZANq5BegHING"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gan.load_weights(\"/content/gdrive/My Drive/SimpleGANS/Checkpoint6/\")"
      ],
      "metadata": {
        "id": "BuNMMi7CHYrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=True)\n",
        "\n",
        "epochs = 100\n",
        "gan.fit(dataset, \n",
        "        epochs=epochs,\n",
        "        workers=8,\n",
        "        use_multiprocessing=True,\n",
        "        callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim), cp_callback]\n",
        ")"
      ],
      "metadata": {
        "id": "JZEyIfCsFlIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# super-resolution set up\n",
        "!pip install nnabla-ext-cuda100\n",
        "!git clone https://github.com/sony/nnabla-examples.git\n",
        "%cd nnabla-examples/image-superresolution/esrgan\n",
        "!wget https://nnabla.org/pretrained-models/nnabla-examples/esrgan/esrgan_latest_g.h5"
      ],
      "metadata": {
        "id": "skUSzo6eaEww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# super-resolution from input directory\n",
        "input_image = \"/content/gdrive/MyDrive/SimpleGANS/generated_images_5/generated_img_001_9.png\"\n",
        "!python inference.py --loadmodel esrgan_latest_g.h5 --input_image $input_img"
      ],
      "metadata": {
        "id": "vVpwFyX-Zn_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install imageio\n",
        "!pip -q install scikit-image\n",
        "!pip install git+https://github.com/tensorflow/docs"
      ],
      "metadata": {
        "id": "OMyJ54gZzPUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  { display-mode: \"code\" }\n",
        "from absl import logging\n",
        "import imageio\n",
        "\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow_docs.vis import embed\n",
        "import time\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "\n",
        "from IPython import display\n",
        "from skimage import transform\n",
        "\n",
        "# We could retrieve this value from module.get_input_shapes() if we didn't know\n",
        "# beforehand which module we will be using.\n",
        "\n",
        "\n",
        "\n",
        "# Interpolates between two vectors that are non-zero and don't both lie on a\n",
        "# line going through origin. First normalizes v2 to have the same norm as v1. \n",
        "# Then interpolates between the two vectors on the hypersphere.\n",
        "def interpolate_hypersphere(v1, v2, num_steps):\n",
        "  v1_norm = tf.norm(v1)\n",
        "  v2_norm = tf.norm(v2)\n",
        "  v2_normalized = v2 * (v1_norm / v2_norm)\n",
        "\n",
        "  vectors = []\n",
        "  for step in range(num_steps):\n",
        "    interpolated = v1 + (v2_normalized - v1) * step / (num_steps - 1)\n",
        "    interpolated_norm = tf.norm(interpolated)\n",
        "    interpolated_normalized = interpolated * (v1_norm / interpolated_norm)\n",
        "    vectors.append(interpolated_normalized)\n",
        "  return tf.stack(vectors)\n",
        "\n",
        "# Simple way to display an image.\n",
        "def display_image(image):\n",
        "  image = tf.constant(image)\n",
        "  image = tf.image.convert_image_dtype(image, tf.uint8)\n",
        "  return PIL.Image.fromarray(image.numpy())\n",
        "\n",
        "# Given a set of images, show an animation.\n",
        "def animate(images):\n",
        "  images = np.array(images)\n",
        "  converted_images = np.clip(images * 255, 0, 255).astype(np.uint8)\n",
        "  imageio.mimsave('./animation.gif', converted_images)\n",
        "  return embed.embed_file('./animation.gif')\n",
        "\n",
        "logging.set_verbosity(logging.ERROR)"
      ],
      "metadata": {
        "id": "EgAly_W52HNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interpolate_between_vectors():\n",
        "  v1 = tf.random.normal([256])\n",
        "  v2 = tf.random.normal([256])\n",
        "\n",
        "  # Creates a tensor with 25 steps of interpolation between v1 and v2.\n",
        "  vectors = interpolate_hypersphere(v1, v2, 40)\n",
        "\n",
        "  # Uses module to generate images from the latent space.\n",
        "  interpolated_images = gan.generator.predict(vectors)\n",
        "\n",
        "  return interpolated_images\n",
        "\n",
        "interpolated_images = interpolate_between_vectors()\n",
        "animate(interpolated_images)"
      ],
      "metadata": {
        "id": "88F2vrZLyAmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display random examples\n",
        "plt.figure(figsize=(20,20)) # specifying the overall grid size\n",
        "\n",
        "for i in range(25):\n",
        "    generated_images = gan.generator.predict(tf.random.normal(shape=(10, 256)))\n",
        "    generated_images *= 255\n",
        "    plt.subplot(5,5,i+1)    # the number of images in the grid is 5*5 (25)\n",
        "    img = keras.preprocessing.image.array_to_img(generated_images[0])\n",
        "    plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XK4rjdQ6Fpbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gan.generator.save('stable_20_epochs_tanh_celeba.h5')"
      ],
      "metadata": {
        "id": "esT7l0i9Fvb8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}