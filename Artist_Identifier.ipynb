{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Artist_Identifier.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOjpF2Oi119ivCKeU3wVa1v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mattberg88/Colab/blob/develop/Artist_Identifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sT76He4YMe-E"
      },
      "outputs": [],
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download ansonnnnn/historic-art"
      ],
      "metadata": {
        "id": "xWzAH0G1OFLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/historic-art.zip\" -d \"/content/\""
      ],
      "metadata": {
        "id": "LULWYXFWRaKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from  matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.applications import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "from PIL import Image\n",
        "tf.config.list_physical_devices('GPU')\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "os.getcwd()"
      ],
      "metadata": {
        "id": "4OYVykS4OYsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "artwork_df = pd.read_csv(\"complete/artwork_dataset.csv\", index_col=0)\n",
        "dirs = []\n",
        "for idx, x in enumerate(artwork_df[\"artist\"]):\n",
        "    dirs.append(f\"complete/artwork/{idx}.jpg\")\n",
        "artwork_df[\"dir\"] = dirs\n",
        "print(artwork_df)\n",
        "\n",
        "artists = np.unique(list(artwork_df[\"artist\"]))"
      ],
      "metadata": {
        "id": "qHdJiVDgOamS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, horizontal_flip=True, vertical_flip=True, validation_split=0.2)\n",
        "train_generator = train_datagen.flow_from_dataframe(dataframe=artwork_df, x_col=\"dir\", y_col=\"artist\", class_mode=\"categorical\", target_size=(224,224), batch_size=16, subset=\"training\", shuffle=True, classes=list(artists))\n",
        "valid_generator = train_datagen.flow_from_dataframe(dataframe=artwork_df, x_col=\"dir\", y_col=\"artist\", class_mode=\"categorical\", target_size=(224,224), batch_size=16, subset=\"validation\", shuffle=True, classes=list(artists))\n",
        "train_input_shape = (224, 224,3)"
      ],
      "metadata": {
        "id": "SYk9gUlXUs5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.resnet50.ResNet50(weights='imagenet', include_top=False, input_shape=train_input_shape)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "X = base_model.output\n",
        "X = tf.keras.layers.Flatten()(X)\n",
        "\n",
        "X = Dense(512, kernel_initializer='he_uniform')(X)\n",
        "X = tf.keras.layers.BatchNormalization()(X)\n",
        "X = Activation('relu')(X)\n",
        "\n",
        "X = Dense(16, kernel_initializer='he_uniform')(X)\n",
        "X = tf.keras.layers.BatchNormalization()(X)\n",
        "X = Activation('relu')(X)\n",
        "\n",
        "output = Dense(len(artists), activation='softmax')(X)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "optimizer = tf.keras.optimizers.Adam(lr=0.0001)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer, \n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "vXFY6wJjVSZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "checkpoint_path = \"/content/gdrive/My Drive/Artist_Identifier/Checkpoints\"\n"
      ],
      "metadata": {
        "id": "d82TG2hZZVRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(checkpoint_path)"
      ],
      "metadata": {
        "id": "yf0R6FU1x10V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, \n",
        "                              verbose=1, mode='auto')\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=True)\n",
        "\n",
        "model.fit_generator(generator=train_generator, \n",
        "                              steps_per_epoch=train_generator.samples // batch_size,\n",
        "                              validation_data=valid_generator,\n",
        "                              validation_steps=valid_generator.samples // batch_size,\n",
        "                              shuffle=True, \n",
        "                              use_multiprocessing=True,\n",
        "                              verbose=1, \n",
        "                              epochs=50,\n",
        "                              workers=7,\n",
        "                              callbacks=[cp_callback, reduce_lr])"
      ],
      "metadata": {
        "id": "_2SRLcxRVtID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import *\n",
        "artwork_df[\"dir\"]\n",
        "content_path = \"/content/\"\n",
        "\n",
        "\n",
        "random_piece = random.choice(artwork_df[\"dir\"])\n",
        "artist_index = list(artwork_df[\"dir\"]).index(random_piece )\n",
        "random_artist = artwork_df[\"artist\"][artist_index]\n",
        "random_image_file = content_path + random_piece\n",
        "file_to_test = \"/content/rembrandt.png\"\n",
        "# Original image\n",
        "\n",
        "test_image = image.load_img(file_to_test, target_size=(train_input_shape[0:2]))\n",
        "\n",
        "# Predict artist\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image /= 255.\n",
        "test_image = np.expand_dims(test_image, axis=0)\n",
        "\n",
        "prediction = model.predict(test_image)\n",
        "prediction_probability = np.amax(prediction)\n",
        "prediction_idx = np.argmax(prediction)\n",
        "\n",
        "labels = train_generator.class_indices\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "\n",
        "title = \"Predicted artist = {}\\nPrediction probability = {:.2f} %\" \\\n",
        "            .format(labels[prediction_idx].replace('_', ' '), prediction_probability*100)\n",
        "\n",
        "\n",
        "# title = \"Actual artist = {}\\nPredicted artist = {}\\nPrediction probability = {:.2f} %\" \\\n",
        "#             .format(random_artist.replace('_', ' '), labels[prediction_idx].replace('_', ' '),\n",
        "#                     prediction_probability*100)\n",
        "\n",
        "# Print image\n",
        "fig, axes = plt.subplots()\n",
        "\n",
        "axes.imshow(plt.imread(file_to_test))\n",
        "axes.set_title(title)\n",
        "axes.axis('off')\n"
      ],
      "metadata": {
        "id": "-zXoxM7PxDyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import *\n",
        "\n",
        "n = 5\n",
        "fig, axes = plt.subplots(1, n, figsize=(25,10))\n",
        "images_dir = \"/content/complete/artwork\"\n",
        "for i in range(n):\n",
        "    random_artist = random.choice(list(artwork_df[\"artist\"]))\n",
        "    random_artist_id = list(artwork_df[\"artist\"]).index(random_artist)\n",
        "    # random_image = random.choice(os.listdir(os.path.join(images_dir, random_artist_id)))\n",
        "    random_image_file = os.path.join(images_dir, str(random_artist_id) + \".jpg\")\n",
        "\n",
        "    # Original image\n",
        "\n",
        "    test_image = image.load_img(random_image_file, target_size=(train_input_shape[0:2]))\n",
        "\n",
        "    # Predict artist\n",
        "    test_image = image.img_to_array(test_image)\n",
        "    test_image /= 255.\n",
        "    test_image = np.expand_dims(test_image, axis=0)\n",
        "\n",
        "    prediction = model.predict(test_image)\n",
        "    prediction_probability = np.amax(prediction)\n",
        "    prediction_idx = np.argmax(prediction)\n",
        "\n",
        "    labels = train_generator.class_indices\n",
        "    labels = dict((v,k) for k,v in labels.items())\n",
        "\n",
        "\n",
        "    title = \"Actual artist = {}\\nPredicted artist = {}\\nPrediction probability = {:.2f} %\" \\\n",
        "                .format(random_artist.replace('_', ' '), labels[prediction_idx].replace('_', ' '),\n",
        "                        prediction_probability*100)\n",
        "\n",
        "    # Print image\n",
        "    axes[i].imshow(plt.imread(random_image_file))\n",
        "    axes[i].set_title(title)\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gS4GRPr5gvn-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}